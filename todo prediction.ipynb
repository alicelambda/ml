{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "from google.cloud import datastore\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \\\n",
    "    \"/home/alice/Downloads/HCL-customer-application-c05a56fa9ccc.json\"\n",
    "\n",
    "client = datastore.Client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load title and Subject data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(kind=\"tododata\")\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "for i in query.fetch():\n",
    "    x.append([i['subject'], i['title']])\n",
    "    y.append([i['totalcoins']])\n",
    "    z.append(i['prev'])\n",
    "y = np.asarray(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(i) for i in z])\n",
    "max_length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "title = CountVectorizer(min_df=0, lowercase=False)\n",
    "title.fit([item['title'] for span in z for item in span])\n",
    "subject = CountVectorizer(min_df=0, lowercase=False)\n",
    "subject.fit([item['subject'] for span in z for item in span])\n",
    "data = []\n",
    "for i in z:\n",
    "    titles = title.transform([ent['title'] for ent in i]).toarray()\n",
    "    subjects = subject.transform([ent['subject'] for ent in i]).toarray()\n",
    "    time = np.asarray([[ent['time']] for ent in i]).reshape(-1,1)\n",
    "    dat = np.concatenate((titles, subjects,time), axis=1)\n",
    "    data.append(dat)\n",
    "    \n",
    "prev = pad_sequences(data,padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert both title and subject to one hot encoded matrices because the datasets are both categorical and orthogonal to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCategorical(data):\n",
    "    vectorizer.fit(data)\n",
    "    return vectorizer.transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = toCategorical([i[1] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = toCategorical([i[0] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((title,subjects),axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize the prediction values to aid the neural net in fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_train, vec_test, y_train, y_test,prev_train ,prev_test = train_test_split(x, y,prev, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 62)\n",
      "(43, 25, 60)\n",
      "(43, 1)\n"
     ]
    }
   ],
   "source": [
    "print(vec_train.shape)\n",
    "print(prev_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 25, 60)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 3)            585         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 62)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 3)            0           gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 65)           0           input_10[0][0]                   \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            528         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            9           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,122\n",
      "Trainable params: 1,122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Concatenate, GRU, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "prev_input = Input((prev.shape[1],prev.shape[2],))\n",
    "vector_input = Input((x.shape[1],))\n",
    "\n",
    "\n",
    "\n",
    "conv_layer = GRU(3)(prev_input)\n",
    "flat_layer = Flatten()(conv_layer)\n",
    "\n",
    "concat_layer = Concatenate()([vector_input, flat_layer])\n",
    "output = Dense(8)(concat_layer)\n",
    "coins = Dense(1)(output)\n",
    "\n",
    "model = Model(inputs=[vector_input,prev_input],outputs=coins)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 1530321.5000 - mae: 1161.5016 - val_loss: 1697826.1250 - val_mae: 1239.5679\n",
      "Epoch 2/70\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1528424.0000 - mae: 1160.7073 - val_loss: 1695678.5000 - val_mae: 1238.7667\n",
      "Epoch 3/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1526432.3750 - mae: 1159.8442 - val_loss: 1693158.1250 - val_mae: 1237.8267\n",
      "Epoch 4/70\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1524027.0000 - mae: 1158.8483 - val_loss: 1690327.6250 - val_mae: 1236.7651\n",
      "Epoch 5/70\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1521505.5000 - mae: 1157.7349 - val_loss: 1687013.1250 - val_mae: 1235.5186\n",
      "Epoch 6/70\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1518425.5000 - mae: 1156.4382 - val_loss: 1683213.5000 - val_mae: 1234.0808\n",
      "Epoch 7/70\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1514903.7500 - mae: 1154.9364 - val_loss: 1678797.1250 - val_mae: 1232.4005\n",
      "Epoch 8/70\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1510694.0000 - mae: 1153.1592 - val_loss: 1673736.0000 - val_mae: 1230.4602\n",
      "Epoch 9/70\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1505954.0000 - mae: 1151.1417 - val_loss: 1667918.0000 - val_mae: 1228.2126\n",
      "Epoch 10/70\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1500542.5000 - mae: 1148.7758 - val_loss: 1661294.8750 - val_mae: 1225.6362\n",
      "Epoch 11/70\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1494228.5000 - mae: 1146.0538 - val_loss: 1653914.5000 - val_mae: 1222.7509\n",
      "Epoch 12/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1487153.1250 - mae: 1143.0334 - val_loss: 1645858.5000 - val_mae: 1219.5880\n",
      "Epoch 13/70\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1479928.2500 - mae: 1139.7415 - val_loss: 1637093.5000 - val_mae: 1216.1434\n",
      "Epoch 14/70\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1471726.3750 - mae: 1136.1600 - val_loss: 1627777.5000 - val_mae: 1212.4698\n",
      "Epoch 15/70\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1462764.5000 - mae: 1132.3704 - val_loss: 1617979.2500 - val_mae: 1208.5964\n",
      "Epoch 16/70\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1453696.7500 - mae: 1128.3563 - val_loss: 1607604.0000 - val_mae: 1204.4794\n",
      "Epoch 17/70\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1444528.3750 - mae: 1124.0907 - val_loss: 1596541.5000 - val_mae: 1200.0815\n",
      "Epoch 18/70\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1433585.5000 - mae: 1119.5751 - val_loss: 1585123.5000 - val_mae: 1195.5204\n",
      "Epoch 19/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1423276.1250 - mae: 1114.8533 - val_loss: 1573137.8750 - val_mae: 1190.7096\n",
      "Epoch 20/70\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1411870.0000 - mae: 1109.8340 - val_loss: 1560588.0000 - val_mae: 1185.6538\n",
      "Epoch 21/70\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1400182.5000 - mae: 1104.5093 - val_loss: 1547408.0000 - val_mae: 1180.3262\n",
      "Epoch 22/70\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1387799.5000 - mae: 1098.9006 - val_loss: 1533610.0000 - val_mae: 1174.7241\n",
      "Epoch 23/70\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1375148.1250 - mae: 1093.1124 - val_loss: 1519252.7500 - val_mae: 1168.8683\n",
      "Epoch 24/70\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1361789.6250 - mae: 1086.9930 - val_loss: 1504303.2500 - val_mae: 1162.7461\n",
      "Epoch 25/70\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1347940.8750 - mae: 1080.7275 - val_loss: 1488848.5000 - val_mae: 1156.3844\n",
      "Epoch 26/70\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1334003.7500 - mae: 1074.0885 - val_loss: 1472764.8750 - val_mae: 1149.7333\n",
      "Epoch 27/70\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1318875.7500 - mae: 1067.2346 - val_loss: 1456405.8750 - val_mae: 1142.9215\n",
      "Epoch 28/70\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1303887.7500 - mae: 1060.2151 - val_loss: 1439487.5000 - val_mae: 1135.8417\n",
      "Epoch 29/70\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1288684.8750 - mae: 1052.9050 - val_loss: 1422098.0000 - val_mae: 1128.5267\n",
      "Epoch 30/70\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1272491.5000 - mae: 1045.4122 - val_loss: 1404380.3750 - val_mae: 1121.0135\n",
      "Epoch 31/70\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1256565.6250 - mae: 1037.7040 - val_loss: 1386088.0000 - val_mae: 1113.2136\n",
      "Epoch 32/70\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1240093.2500 - mae: 1029.6892 - val_loss: 1367475.1250 - val_mae: 1105.2246\n",
      "Epoch 33/70\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1223129.6250 - mae: 1021.4846 - val_loss: 1348464.8750 - val_mae: 1097.0038\n",
      "Epoch 34/70\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1205967.5000 - mae: 1013.0884 - val_loss: 1329036.7500 - val_mae: 1088.5343\n",
      "Epoch 35/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1187952.5000 - mae: 1004.3483 - val_loss: 1309416.7500 - val_mae: 1079.9113\n",
      "Epoch 36/70\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1170231.2500 - mae: 995.4761 - val_loss: 1289276.1250 - val_mae: 1070.9962\n",
      "Epoch 37/70\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1152357.6250 - mae: 986.3859 - val_loss: 1268692.7500 - val_mae: 1061.8167\n",
      "Epoch 38/70\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1133889.7500 - mae: 977.1609 - val_loss: 1247885.5000 - val_mae: 1052.4535\n",
      "Epoch 39/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1115189.3750 - mae: 967.4144 - val_loss: 1226806.1250 - val_mae: 1042.8856\n",
      "Epoch 40/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1095467.8750 - mae: 957.7046 - val_loss: 1205729.6250 - val_mae: 1033.2251\n",
      "Epoch 41/70\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1076848.7500 - mae: 947.7996 - val_loss: 1184225.3750 - val_mae: 1023.2744\n",
      "Epoch 42/70\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1057575.8750 - mae: 937.6111 - val_loss: 1162333.8750 - val_mae: 1013.0598\n",
      "Epoch 43/70\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1038527.0625 - mae: 927.1762 - val_loss: 1140077.5000 - val_mae: 1002.5680\n",
      "Epoch 44/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1018995.0000 - mae: 916.5456 - val_loss: 1117638.7500 - val_mae: 991.8820\n",
      "Epoch 45/70\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 999010.2500 - mae: 905.6672 - val_loss: 1095275.1250 - val_mae: 981.1092\n",
      "Epoch 46/70\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 978573.1875 - mae: 894.7148 - val_loss: 1072954.8750 - val_mae: 970.2496\n",
      "Epoch 47/70\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 958683.0625 - mae: 883.5108 - val_loss: 1050590.5000 - val_mae: 959.2396\n",
      "Epoch 48/70\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 939273.1875 - mae: 872.1657 - val_loss: 1027815.0000 - val_mae: 947.9014\n",
      "Epoch 49/70\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 918514.6250 - mae: 860.7217 - val_loss: 1005265.9375 - val_mae: 936.5463\n",
      "Epoch 50/70\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 897975.8125 - mae: 849.0796 - val_loss: 982820.8125 - val_mae: 925.0916\n",
      "Epoch 51/70\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 879474.6250 - mae: 837.3735 - val_loss: 959826.0625 - val_mae: 913.2267\n",
      "Epoch 52/70\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 858349.7500 - mae: 825.3182 - val_loss: 937147.5625 - val_mae: 901.3826\n",
      "Epoch 53/70\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 839223.6250 - mae: 813.1566 - val_loss: 914230.4375 - val_mae: 889.2512\n",
      "Epoch 54/70\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 818309.0000 - mae: 800.8094 - val_loss: 891732.4375 - val_mae: 877.1710\n",
      "Epoch 55/70\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 798754.6250 - mae: 790.0473 - val_loss: 869072.0000 - val_mae: 864.8502\n",
      "Epoch 56/70\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 778891.3125 - mae: 780.4585 - val_loss: 846538.9375 - val_mae: 852.4353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/70\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 759851.8125 - mae: 771.2279 - val_loss: 823982.0000 - val_mae: 839.8162\n",
      "Epoch 58/70\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 740549.8125 - mae: 761.0443 - val_loss: 801560.0000 - val_mae: 827.0815\n",
      "Epoch 59/70\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 720615.9375 - mae: 750.6723 - val_loss: 779604.3750 - val_mae: 814.4233\n",
      "Epoch 60/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 702396.8750 - mae: 741.1511 - val_loss: 757533.2500 - val_mae: 801.5068\n",
      "Epoch 61/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 683253.1875 - mae: 731.1608 - val_loss: 735855.3750 - val_mae: 788.6097\n",
      "Epoch 62/70\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 663741.0000 - mae: 721.0296 - val_loss: 714631.7500 - val_mae: 775.7791\n",
      "Epoch 63/70\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 646501.0000 - mae: 710.9418 - val_loss: 693210.5000 - val_mae: 762.6350\n",
      "Epoch 64/70\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 627740.6250 - mae: 700.2513 - val_loss: 672520.5625 - val_mae: 749.8127\n",
      "Epoch 65/70\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 609522.5000 - mae: 689.9877 - val_loss: 652027.5000 - val_mae: 738.0955\n",
      "Epoch 66/70\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 593024.3750 - mae: 680.5188 - val_loss: 631605.2500 - val_mae: 726.2316\n",
      "Epoch 67/70\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 575248.6250 - mae: 670.6205 - val_loss: 611625.0000 - val_mae: 714.4041\n",
      "Epoch 68/70\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 558245.1250 - mae: 660.6288 - val_loss: 592071.1875 - val_mae: 702.6083\n",
      "Epoch 69/70\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 541769.3125 - mae: 651.4976 - val_loss: 572803.1250 - val_mae: 690.7594\n",
      "Epoch 70/70\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 524601.0625 - mae: 640.9351 - val_loss: 554107.2500 - val_mae: 679.0486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0272eef970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"rewardlogs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit((vec_train,prev_train), y_train, \n",
    "          validation_data=((vec_test,prev_test),y_test),\n",
    "          batch_size=15, \n",
    "          epochs=70,\n",
    "          verbose=1,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 373843), started 0:11:57 ago. (Use '!kill 373843' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3ff4c08d75e46149\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3ff4c08d75e46149\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6007;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir rewardlogs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
