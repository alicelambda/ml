{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "from google.cloud import datastore\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \\\n",
    "    \"/home/alice/Downloads/HCL-customer-application-c05a56fa9ccc.json\"\n",
    "\n",
    "client = datastore.Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = client.query(kind=\"tododata\")\n",
    "x = []\n",
    "y = []\n",
    "for i in query.fetch():\n",
    "    x.append([i['subject'], i['title']])\n",
    "    y.append([i['totalcoins']])\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=False, max_df=1.0, max_features=None, min_df=0,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit([i[1] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = vectorizer.transform([i[1] for i in x]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit([i[0] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = le.transform([i[0] for i in x])\n",
    "subjects = subjects.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((titles,subjects),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 12)\n",
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(12, activation='relu',input_shape=(x.shape[1],)))\n",
    "# Add an output layer with 10 output units:\n",
    "model.add(layers.Dense(6, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(data, mean_data =None, std_data =None):\n",
    "    if not mean_data:\n",
    "        mean_data = np.mean(data)\n",
    "    if not std_data:\n",
    "        std_data = np.std(data)\n",
    "    norm_data = (data-mean_data)/std_data\n",
    "    return norm_data, mean_data, std_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "\n",
    "Y_train, ymean_data, ystd_data = Normalize(y_train)\n",
    "Y_test,_,_ = Normalize(y_test, ymean_data, ystd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0041 - mae: 0.0412 - val_loss: 8.5543 - val_mae: 2.9083\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 8.5678 - val_mae: 2.9104\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 8.5835 - val_mae: 2.9129\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 4.7315e-04 - mae: 0.0164 - val_loss: 8.5999 - val_mae: 2.9155\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 7.9284e-05 - mae: 0.0086 - val_loss: 8.6165 - val_mae: 2.9182\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 7.5043e-05 - mae: 0.0072 - val_loss: 8.6347 - val_mae: 2.9212\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 3.6511e-04 - mae: 0.0102 - val_loss: 8.6488 - val_mae: 2.9236\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 8.2047e-04 - mae: 0.0124 - val_loss: 8.6579 - val_mae: 2.9251\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0013 - mae: 0.0157 - val_loss: 8.6612 - val_mae: 2.9256\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0017 - mae: 0.0193 - val_loss: 8.6586 - val_mae: 2.9252\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 8.6502 - val_mae: 2.9238\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - mae: 0.0233 - val_loss: 8.6366 - val_mae: 2.9214\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0018 - mae: 0.0238 - val_loss: 8.6186 - val_mae: 2.9184\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0015 - mae: 0.0235 - val_loss: 8.5973 - val_mae: 2.9148\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 8.5739 - val_mae: 2.9108\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.7647e-04 - mae: 0.0209 - val_loss: 8.5495 - val_mae: 2.9067\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.8834e-04 - mae: 0.0190 - val_loss: 8.5255 - val_mae: 2.9026\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0120e-04 - mae: 0.0169 - val_loss: 8.5028 - val_mae: 2.8987\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2477e-04 - mae: 0.0147 - val_loss: 8.4825 - val_mae: 2.8953\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.4579e-04 - mae: 0.0154 - val_loss: 8.4658 - val_mae: 2.8924\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.3486e-04 - mae: 0.0182 - val_loss: 8.4540 - val_mae: 2.8904\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.5502e-04 - mae: 0.0204 - val_loss: 8.4457 - val_mae: 2.8891\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.7025e-04 - mae: 0.0220 - val_loss: 8.4411 - val_mae: 2.8883\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5210e-04 - mae: 0.0229 - val_loss: 8.4401 - val_mae: 2.8881\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.8381e-04 - mae: 0.0231 - val_loss: 8.4425 - val_mae: 2.8886\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.6144e-04 - mae: 0.0227 - val_loss: 8.4480 - val_mae: 2.8895\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9242e-04 - mae: 0.0217 - val_loss: 8.4561 - val_mae: 2.8909\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.9230e-04 - mae: 0.0202 - val_loss: 8.4662 - val_mae: 2.8926\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.8035e-04 - mae: 0.0183 - val_loss: 8.4778 - val_mae: 2.8945\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7528e-04 - mae: 0.0161 - val_loss: 8.4905 - val_mae: 2.8967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdc50924130>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"rewardlogs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          validation_data=(X_test,Y_test), \n",
    "          batch_size=20, \n",
    "          epochs=30,\n",
    "          verbose=1,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 40440), started 0:02:28 ago. (Use '!kill 40440' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cc6882c67fe99d3b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cc6882c67fe99d3b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6007;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir rewardlogs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dev', 'bayesian optimization'], ['dev', 'GCP MOre data'], ['m340l', 'pass fail m340l'], ['dev', 'meow UI updates'], ['dev', 'meow UI updates'], ['dev', 'meow UI updates'], ['dev', 'meow UI updates'], ['dev', 'meow UI updates']]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
